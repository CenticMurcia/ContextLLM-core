{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fusion corrective RAG with parent/child strategy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No ejecutar\n",
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.vectorstores import VectorStore \n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from typing import List\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPConnectionPool(host='80.73.154.76', port=18001): Max retries exceeded with url: /ollama (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x700ffee4a710>, 'Connection to 80.73.154.76 timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connection.py:208\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPConnection object at 0x700ffee4a710>, 'Connection to 80.73.154.76 timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='80.73.154.76', port=18001): Max retries exceeded with url: /ollama (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x700ffee4a710>, 'Connection to 80.73.154.76 timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m passw \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20centic05\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Prueba la conexión\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://80.73.154.76:18001/ollama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43musuario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus Code:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPConnectionPool(host='80.73.154.76', port=18001): Max retries exceeded with url: /ollama (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x700ffee4a710>, 'Connection to 80.73.154.76 timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Credenciales de autenticación\n",
    "\n",
    "usuario = \"joseacentic\"\n",
    "passw = \"20centic05\"\n",
    "\n",
    "# Prueba la conexión\n",
    "response = requests.get(\"http://80.73.154.76:18001/ollama\", auth=(usuario, passw))\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response Text:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96187/1480801614.py:8: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = Ollama(base_url=\"http://10.7.15.205:11434/\",\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'question', 'product_unitPrice', 'tenant_currency', 'product_summaryDescription', '\\n    \"response\"', 'product_name'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m pprize \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m29.99\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the weather like in Paris?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtenant_currency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_summaryDescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpdescrp\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_unitPrice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpprize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtenant_locale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain/chains/base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    607\u001b[0m         _output_key\n\u001b[1;32m    608\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    612\u001b[0m         _output_key\n\u001b[1;32m    613\u001b[0m     ]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain/chains/base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m     inputs,\n\u001b[1;32m    154\u001b[0m     run_id,\n\u001b[1;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/context/lib/python3.10/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'question', 'product_unitPrice', 'tenant_currency', 'product_summaryDescription', '\\n    \"response\"', 'product_name'}"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = Ollama(base_url=\"http://10.7.15.205:11434/\",\n",
    "             model=\"qwen2.5:14b\",\n",
    "             verbose=True,\n",
    "             callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "#llm.invoke('Hola')\n",
    "\n",
    "template = \"\"\" \n",
    "## Rol \n",
    "You are an apparel shopping assistant.\n",
    "\n",
    "You **must always** follow these rules:\n",
    "\n",
    "Use Markdown and emojis to enhance readability.\n",
    "Never mention or discuss other e-commerce platforms.\n",
    "Always use currency {tenant_currency} with two decimal places when referencing prices.\n",
    "Your output must always be formatted in JSON using the keys \"response\", \"isAnswered\", and \"isLicitQuestion\".\n",
    "\n",
    "## Context Analysis:\n",
    "You will evaluate the context provided below to determine whether the buyer's question is licit:\n",
    "\n",
    "**Product Details**:\n",
    "\n",
    "Name: {product_name}\n",
    "Description: {product_summaryDescription}\n",
    "Price: {product_unitPrice}\n",
    "Buyer Question: {question}\n",
    "\n",
    "**Rules for Licit Questions:**\n",
    "A question is licit if it pertains to the product's characteristics, features, pricing, availability, or other directly relevant details.\n",
    "If the question is **not licit**, your response **must only be**: \"I can't help you with that\".\n",
    "**JSON Output:**\n",
    "\"response\": A concise, friendly answer to the buyer's question, formatted with Markdown. This field is mandatory only if \"isLicitQuestion\": true. \n",
    "\"isAnswered\": true if the question is licit, otherwise false.\n",
    "\"isLicitQuestion\": true if the question is licit, otherwise false.\n",
    "\n",
    "## Step-by-step Process:\n",
    "\n",
    "1. Evaluate if the question is licit:\n",
    "      If yes, generate a detailed response using product details.\n",
    "      \n",
    "      If no, output only:\n",
    "{\n",
    "    \"response\": \"I can't help you with that\",\n",
    "    \"isAnswered\": false,\n",
    "    \"isLicitQuestion\": false\n",
    "}\n",
    "2.Format your output strictly in JSON as described above.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"tenant_currency\", \"product_name\",\"product_summaryDescription\",\"product_unitPrice\", \"question\",\"tenant_locale\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "pname = \"Wool Knit Scarf\"\n",
    "pdescrp = \"Cozy wool knit scarf to keep you warm during the chilly months.\"\n",
    "pprize = \"29.99\"\n",
    "question = \"What is the weather like in Paris?\"\n",
    "llm_chain.run(input={\"tenant_currency\":\"\", \"product_name\":pname,\"product_summaryDescription\":pdescrp,\"product_unitPrice\":pprize, \"question\":question,\"tenant_locale\":\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "myFile = 'annualreport.pdf'\n",
    "loader = PyPDFLoader(\"DATA/\" + myFile)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "parent_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        length_function=len\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Nota:</u> \n",
    "\n",
    "Ver si es posible unir las dos celdas siguientes en una única base de datos añadiendo una nueva colección de documentos. \n",
    "\n",
    "No está claro por la forma en la que se tiene que acceder a los documentos de la base de datos desde el retriever personalizado. \n",
    "\n",
    "<del>IMPORTANTE: Comprobar que cuando se define el store = InMemoryStore() dos veces (una para cada modelo de embeddings) tiene la misma referencia (doc_id en el metadata) porque si no estaremos recuperando documentos iguales mas de una vez. </del> Tienen referencias distintas\n",
    "\n",
    "<del>OJO puede ser que no haya ningun problema puesto que dentro de la Store se guarde el mismo documento dos veces con dos ids diferentes. (Probar) </del> Esto es lo que ocurre\n",
    "\n",
    "<h4><b>Problema en el reranking al meter el parent child: <u> SOLUCIONADO  </u> </b></h4>  \n",
    "\n",
    "Cuando no se usaba el parent child no habia problema al usar el dumnps(doc) para comprobar los que eran iguales y los que no. Ahora como se generan doc_id diferentes en función de las vectorstore si dos documentos iguales vienen de diferentes bases de datos\n",
    "el dumps() no los asocia como iguales puesto que no tienen el mismo metadata. entonces en el reranking se meten de nuevo a 0 y no suma puntuación si ya está metido en la lista \n",
    "\n",
    "\n",
    "Se arreglaría todo metiendo en la vectorstore nueva los documentos con los mismos doc_id que en la bd anterior. --- > No se ha solucionado así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121947/954869930.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "vectorstore = Chroma(\n",
    "        collection_name=\"documents\",\n",
    "        persist_directory=\"DATA/chroma_db\",\n",
    "        embedding_function=hugg_embeddings\n",
    "    )\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "full_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")\n",
    "\n",
    "full_retriever.add_documents(data, ids = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_bgem3 = Chroma(\n",
    "        collection_name=\"documents\",\n",
    "        persist_directory=\"DATA/chroma_db\",\n",
    "        embedding_function=hugg_emb_bgem3\n",
    "    )\n",
    "\n",
    "#store_bge = InMemoryStore()\n",
    "\n",
    "full_retriever_bge = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore_bgem3,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")\n",
    "\n",
    "full_retriever_bge.add_documents(data, ids = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '1c9f26d6-14b6-46a8-b33b-c102e347b249', 'page': 40, 'source': 'DATA/annualreport.pdf'}, page_content='number of AIM quoted and private \\ncompany boards.January 2020 October 2005\\nHaroon is amongst the most experienced \\nCEOs in the health and social care \\nsector and one of the UK’s leading \\nentrepreneurs and philanthropists. Along \\nwith his brother Farouq, he co-founded \\nCareTech. As Group CEO he actively leads \\nthe day-to-day running of the Group \\nand its international expansion, and has'),\n",
       " Document(metadata={'doc_id': '1c9f26d6-14b6-46a8-b33b-c102e347b249', 'page': 40, 'source': 'DATA/annualreport.pdf'}, page_content='with his brother Farouq, he co-founded \\nCareTech. As Group CEO he actively leads \\nthe day-to-day running of the Group \\nand its international expansion, and has \\nbeen instrumental in assembling a highly \\ntalented leadership team, to support \\nthe continued growth of the business. \\nHaroon brings commercial acumen, \\nrelated industry experience and property \\nknowledge. He has a deep commitment'),\n",
       " Document(metadata={'doc_id': '3002869c-fc1a-4cbf-82ad-9e9e6224d46a', 'page': 2, 'source': 'DATA/annualreport.pdf'}, page_content='is shared by our staff as well as by the people \\nin our care. We want everyone in the CareTech \\nfamily to have a bright future and we work \\ntirelessly towards that aim. \\nHaroon Sheikh\\nGroup Chief Executive Officer\\n6 December 2021\\nOur Purpose\\nWe enable children, young people \\nand adults with complex needs to \\nmake their own life choices, and build \\nconfidence and independence to live,'),\n",
       " Document(metadata={'doc_id': '4adca24a-79d1-4087-bfbd-d8127c4d544a', 'page': 50, 'source': 'DATA/annualreport.pdf'}, page_content='Haroon Sheikh and Christopher Dickinson under the Sharesave Scheme.\\nChristopher Dickinson has an interest in 155,250 Ordinary Shares in CareTech pursuant to the Executive Shared Ownership Plan, details of  \\nwhich were announced on 8 November 2019.\\nNone of the options above are subject to clawback arrangements\\nNo other Director has any share options in the Group.\\nNon-Executive Director Fees')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_bgem3.similarity_search('Is it true that Haroon Sheikh is the CEO of CareTech?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='number of AIM quoted and private \\ncompany boards.January 2020 October 2005\\nHaroon is amongst the most experienced \\nCEOs in the health and social care \\nsector and one of the UK’s leading \\nentrepreneurs and philanthropists. Along \\nwith his brother Farouq, he co-founded \\nCareTech. As Group CEO he actively leads \\nthe day-to-day running of the Group \\nand its international expansion, and has', metadata={'doc_id': '6ee008de-9630-4bbd-b07a-2ff6b0a85ea3', 'page': 40, 'source': 'DATA/annualreport.pdf'}),\n",
       " Document(page_content='with his brother Farouq, he co-founded \\nCareTech. As Group CEO he actively leads \\nthe day-to-day running of the Group \\nand its international expansion, and has \\nbeen instrumental in assembling a highly \\ntalented leadership team, to support \\nthe continued growth of the business. \\nHaroon brings commercial acumen, \\nrelated industry experience and property \\nknowledge. He has a deep commitment', metadata={'doc_id': '6ee008de-9630-4bbd-b07a-2ff6b0a85ea3', 'page': 40, 'source': 'DATA/annualreport.pdf'}),\n",
       " Document(page_content=\"Awards. In 2019, Haroon and Farouq were \\nwinners of the 'Asian Business of the Year'.\\nHaroon, a graduate of the University \\nof London, is a Founder Trustee of the \\nCareTech Charitable Foundation formed \\nin 2017, and is Chairman of the Trustees, \\nworking closely with the Foundation’s \\nCEO and independent Trustees.Jamie joined the Board as a Non-\\nExecutive Director in 2013. Following\", metadata={'doc_id': '6ee008de-9630-4bbd-b07a-2ff6b0a85ea3', 'page': 40, 'source': 'DATA/annualreport.pdf'}),\n",
       " Document(page_content='is shared by our staff as well as by the people \\nin our care. We want everyone in the CareTech \\nfamily to have a bright future and we work \\ntirelessly towards that aim. \\nHaroon Sheikh\\nGroup Chief Executive Officer\\n6 December 2021\\nOur Purpose\\nWe enable children, young people \\nand adults with complex needs to \\nmake their own life choices, and build \\nconfidence and independence to live,', metadata={'doc_id': 'f5d6c638-4710-43a9-83b7-cbdd5df5834e', 'page': 2, 'source': 'DATA/annualreport.pdf'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search('Is it true that Haroon Sheikh is the CEO of CareTech?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.vectorstores import VectorStore \n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "'''\n",
    "Explicación del retriever, en particular la función _get_relevant_documents() para saber como usar el retriever cuando se quieran añadir más \n",
    "condiciones en el rrf: \n",
    "Esta clase está estructurada para que con las funciones rrf() y get_fused_scores() se puedan ir añadiendo tantos metodos de recuperación de \n",
    "contexto como se quiera. (Siempre que los documentos recuperados tengan un orden concreto, para los que no, ya está el método fused_scores_literal()\n",
    "que asigna a todos los documentos el mismo valor). \n",
    "¿Cómo funciona y se puede automatizar la función _get_relevant_documents()?\n",
    "Supongamos que tenemos n criterios de recuperación de contextos (en este ejemplo tenemos 4, literal, mxbai l2, mxbai cos, bge cos)\n",
    "En primer lugar, se necestita ir calculando los scores de los documentos que vamos obteniendo para ello, se va haciendo uso de la función get_fused_scores()\n",
    "scores1 =  get_fused_scores({},lista1), scores2 = get_fused_scores(scores1,lista2), ... , scoresn = get_fused_scores(scores(n-1), listan)\n",
    "Esto lo que va haciendo es ir acumulando los scores de acuerdo al valor que se ha decidido dar. En este caso, 1/1+rank. \n",
    "Por ultimo una vez tengamos todos los documentos con sus scores se hace uso de la función rrf con los ultimos scores, que se encarga de dar la lista final de \n",
    "documentos ordenada sin los scores ya para que la procese la función del retriever. \n",
    "rrf(scores(n)) puesto que esta función desde dentro ya se encarga de calcular los scores para la ultima lista.\n",
    "'''\n",
    "class CustomRetriever_advanced(BaseRetriever):\n",
    "    '''En este caso se necesitan dos db vectoriales que almacenen los embeddings que genera cada modelo diferente. Se pueden usar\n",
    "    tantos modelos de generación de embeddings como se quiera simplemente habrá que pasar en esta clase del retriever personalizado \n",
    "    las bases de datos correspondientes. También se va a añadir una variable k que será el número de documentos que se quieran recuperar\n",
    "    Por ejemplo si k = 10 pues el retriever generará un contexto con los 10 documentos que mayor score hayan generado. En el caso anterior \n",
    "    que k no se especificaba, en los documentos se metían todos los que se iban recuperando de cada método. '''\n",
    "    vs: VectorStore\n",
    "    vs_2: VectorStore\n",
    "    k: int\n",
    "    '''fused_scores es un diccionario que va a ir actualizando la solucion de rrf por lo que en la primera\n",
    "    iteración fused_scores = {} (diccionario vacio) mientras que para las demás iteraciones será la solución\n",
    "    de esta función junto con las diferentes listas que queramos ir pasandole el rrf'''\n",
    "    \n",
    "    '''\n",
    "    Cada vez que se hace una llamada a la función rrf nos da una lista de objetos Document (sin el score) que están ya listos \n",
    "    para pasar al retrievalQA. Es necesario pasarle la lista de scores que se va obteniendo conforme se van usando técnicas en\n",
    "    el reranking. \n",
    "    '''\n",
    "    def rrf(self,fused_scores):\n",
    "        reranked_results = {doc: score for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)}\n",
    "        #falta pasar estos resultados a una lista de documentos que es lo que devuelve el retriver (loads)\n",
    "        lista_rerank = []\n",
    "        print('Documentos finales (score)')\n",
    "        for doc, score in reranked_results.items():\n",
    "            lista_rerank.append(loads(doc))\n",
    "            print('------')\n",
    "            print(score)\n",
    "        return lista_rerank\n",
    "    \n",
    "    '''\n",
    "    La función get_fused_scores, nos sirve para ir actualizando los scores de una lista de documetnos dada. Por ejemplo, si estamos \n",
    "    en la primera iteración del rrf, previus_fused = {} y esta función devolverá un diccionario actualizado con los documetnos de la lista \n",
    "    y su correspondiente score. Este diccionario será necesario para pasarselo luego en la función rrf. \n",
    "    Cuando no estamos en la primera iteración y previus_fused ya no es un diccionario vacio, se le pasará un diccionario de documentos y \n",
    "    scores junto con una nueva lista que tendrá los documentos que queremos incorporar a la lista de scores. \n",
    "    '''   \n",
    "    def get_fused_scores(self,previus_fused, lista):\n",
    "        for rank, doc in enumerate(lista):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in previus_fused:\n",
    "                previus_fused[doc_str] = 0\n",
    "            previus_score = previus_fused[doc_str]\n",
    "            print(f'scores previos {previus_score}')\n",
    "            previus_fused[doc_str] += 1 / (rank + 1)\n",
    "        return previus_fused\n",
    "    \n",
    "    '''\n",
    "    Este método realiza la misma función que la anterior solo que en esta se ha utilizado para arreglar el problema de tener doc_id diferente para el\n",
    "    mismo chunk en dos bases de datos. Lo que hace es ir metiendo los documentos en una lista y actualizar el metadata de los nuevos que van entrando si \n",
    "    ya se encuentran en la lista. Asi solucionamos el tema de la duplicidad, el resto de funcionamiento es idéntico.\n",
    "    '''\n",
    "    def get_fused_scores_v2(self,previus_fused, lista):\n",
    "        \n",
    "        previus_list = []\n",
    "        for doc, score in previus_fused.items():\n",
    "            previus_list.append(loads(doc))\n",
    "        \n",
    "        for d in lista:\n",
    "            for p_d in previus_list:\n",
    "                if d.page_content == p_d.page_content: \n",
    "                    d.metadata['doc_id'] = p_d.metadata['doc_id']\n",
    "\n",
    "        for rank, doc in enumerate(lista):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in previus_fused:\n",
    "                previus_fused[doc_str] = 0\n",
    "            previus_score = previus_fused[doc_str]\n",
    "            print(f'scores previos {previus_score}')\n",
    "            previus_fused[doc_str] += 1 / (rank + 1)\n",
    "\n",
    "        return previus_fused\n",
    "\n",
    "\n",
    "    '''\n",
    "    Nota: Esta función no haría falta si no se le diera la misma puntuación a cada documento obtenido en la búsqueda literal. Esto se debe a que \n",
    "    cuando se buscan documentos de forma literal todos han de tener el mismo valor. No se puede distinguir de esta manera si hay uno \"mejor\" que otro. \n",
    "    Como aqui tenemos fused_scores = {}, esto significa que si queremos usar esta estrategia siempre tiene que ser los primeros scores que se recopilan, \n",
    "    si no hay que cambiar y pasarle como argumetno unos scores previos y acumular con += 0.5\n",
    "    En resumen no es necesario aqui comprobar lo de la lista auxiliar y cambiar el metadata de doc_id ya que en este caso serían los primeros documentos \n",
    "    que entrarían en la lista y en ningún caso estarían duplicados. \n",
    "    '''\n",
    "    def fused_scores_literal(self, lista):\n",
    "        fused_scores = {}\n",
    "        for doc in lista:\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previus_score = fused_scores[doc_str]\n",
    "            print(f'scores previos {previus_score}')\n",
    "            fused_scores[doc_str] = 0.5\n",
    "        return fused_scores\n",
    "    ''' \n",
    "    Genera una consulta para que sea dinámica la busqueda literal en la base de datos, dada una lista de palabras clave. \n",
    "    El método de busqueda literal en la base de datos chroma, necesita el siguiente formato\n",
    "    {\n",
    "    \"$and\": [\n",
    "        {\"$contains\": \"key_word1\"},\n",
    "        {\"$contains\": \"key_word2\"}\n",
    "        ]\n",
    "    }\n",
    "    Con lo cual, este método en función de las palabras clave que tenga nuestra query, se van añadiendo a la consulta y no se\n",
    "    necesita ir creando una consulta a mano para cada búsqueda literal que tenga diferente numero de palabras clave. \n",
    "    '''\n",
    "    def generaConsulta(self,key_words):\n",
    "        busquedas = []\n",
    "        for w in key_words:\n",
    "            conta = {\"$contains\":str(w)}\n",
    "            busquedas.append(conta)\n",
    "        #Duda: Poner un or en vez de un and. En el caso de que existan muchos keywords puede ser dificil encontrar documentos que los contengan todas. \n",
    "        consulta = {\"$and\": busquedas}\n",
    "        return consulta\n",
    "    \n",
    "    '''Corrective RAG:\n",
    "    La función CRAG, recibe una query (pregunta) y una serie de documentos que han sido recuperados con el objetivo de responder la pregunta\n",
    "    de forma correcta. En este caso, se crea un LLM que sea capaz de evaluar cada uno de estos documentos y decida si su contenido es adecuado\n",
    "    para responder la pregunta. Los documentos que se consideren adecuados son aquellos que se devuelven en esta función. \n",
    "    '''\n",
    "    def CRAG(self, query, docs):\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "            Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "            Here is the user question: {question} \\n\n",
    "            If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "            It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "            Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "            Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\"\"\",\n",
    "            input_variables=[\"question\", \"document\"],\n",
    "        )\n",
    "\n",
    "        retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "        valid_docs = []\n",
    "\n",
    "        for d in docs:\n",
    "            score = retrieval_grader.invoke({\"question\": query, \"document\": d.page_content})\n",
    "            if score['score'] == \"yes\":\n",
    "                valid_docs.append(d)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return valid_docs\n",
    "    \n",
    "    '''\n",
    "    En el RetrievalQA, que se pasa en la cadena, el retriever que se usa por la clase para obtener los diferentes documentos hace uso de una función\n",
    "    llamada get_relevant_documents() que viene predeterminada en el retriever base. Cuando hacemos un retriever personalizado, es necesario crear una\n",
    "    función _get_relevant_documents(), con _ delante del mismo nombre anterior para que a la hora de recuperar documentos la función RetrievalQA haga \n",
    "    uso de la función que hemos personalizado para recuperar los documentos. Solo tenemos que tener en cuenta que al aplicar los cambios que queremos\n",
    "    al personalizar esta función, se devuelva una lista de documentos (objetos Document)\n",
    "    '''\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "        ) -> List[Document]:\n",
    "        #Quitar la parte de spacy pq da error de dependencias, esto es la parte literal !!\n",
    "        '''\n",
    "        spacyModel = spacy.load(\"en_core_web_sm\")\n",
    "        list = self.vs.get(\n",
    "            where_document=self.generaConsulta(spacyModel(query).ents)\n",
    "            )\n",
    "        \n",
    "        literal_docs = []\n",
    "      \n",
    "        for i in range(len(list['ids'])):\n",
    "            doc = Document(page_content=list['documents'][i],metadata=list['metadatas'][i])\n",
    "            literal_docs.append(doc)\n",
    "        '''\n",
    "        \n",
    "        #documentos\n",
    "        docs_l2 = self.vs.similarity_search(query)\n",
    "\n",
    "        docs_simcos = self.vs.similarity_search_by_vector(hugg_embeddings.embed_query(query))\n",
    "        \n",
    "        docs_simcos_bge = self.vs_2.similarity_search_by_vector(hugg_emb_bgem3.embed_query(query))\n",
    "        #Scores acumulados de cada haciendo uso de cada tecnica\n",
    "        #scores_literal = self.fused_scores_literal(literal_docs)\n",
    "\n",
    "        scores_l2 = self.get_fused_scores_v2({},docs_l2)\n",
    "        \n",
    "        scores_simcos = self.get_fused_scores_v2(scores_l2,docs_simcos)\n",
    "\n",
    "        scores_bge = self.get_fused_scores_v2(scores_simcos,docs_simcos_bge)\n",
    "        #Recuperación de documentos\n",
    "        rrf_documents = self.rrf(scores_bge)\n",
    "\n",
    "        #evaluación de los documentos con CRAG.\n",
    "        crag_documents = self.CRAG(query,rrf_documents)\n",
    "\n",
    "        ids = []\n",
    "\n",
    "        for d in crag_documents: \n",
    "            if d.metadata['doc_id'] not in ids: \n",
    "                ids.append(d.metadata['doc_id'])\n",
    "\n",
    "        parent_docs = store.mget(ids)\n",
    "\n",
    "        str_docs = []\n",
    "        docs = []\n",
    "        for pd in parent_docs:\n",
    "            parent_doc_str = dumps(pd)\n",
    "            if parent_doc_str not in str_docs:\n",
    "                if pd is not None:\n",
    "                    str_docs.append(parent_doc_str)\n",
    "                    docs.append(loads(parent_doc_str))\n",
    "\n",
    "        return docs[0:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0.3333333333333333\n",
      "scores previos 1.3333333333333333\n",
      "scores previos 1.8333333333333333\n",
      "scores previos 0.25\n",
      "scores previos 2.1666666666666665\n",
      "scores previos 3.1666666666666665\n",
      "scores previos 0.5\n",
      "scores previos 0.8333333333333333\n",
      "Documentos finales (score)\n",
      "------\n",
      "3.6666666666666665\n",
      "------\n",
      "1.0833333333333333\n",
      "------\n",
      "1.0\n",
      "------\n",
      "0.5\n",
      " {\"score\": \"yes\"} {\n",
      "\"score\": \"yes\"\n",
      "} {\"score\": \"yes\"} {\"score\": \"yes\"}\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a knowledgeable chatbot, here to help with questions of the user.\n",
      "    Your tone should be professional and informative.\n",
      "\n",
      "    Context: and Robert W. Baird for two years until \n",
      "June 2002. Karl set up Ashling Capital \n",
      "LLP in December 2002 to provide \n",
      "consultancy services to quoted \n",
      "and private companies. He sits on a \n",
      "number of AIM quoted and private \n",
      "company boards.January 2020 October 2005\n",
      "Haroon is amongst the most experienced \n",
      "CEOs in the health and social care \n",
      "sector and one of the UK’s leading \n",
      "entrepreneurs and philanthropists. Along \n",
      "with his brother Farouq, he co-founded \n",
      "CareTech. As Group CEO he actively leads \n",
      "the day-to-day running of the Group \n",
      "and its international expansion, and has \n",
      "been instrumental in assembling a highly \n",
      "talented leadership team, to support \n",
      "the continued growth of the business. \n",
      "Haroon brings commercial acumen, \n",
      "related industry experience and property \n",
      "knowledge. He has a deep commitment \n",
      "and passion for delivering high-quality \n",
      "care and support to people with  \n",
      "complex needs. \n",
      "Haroon is Patron and Enterprise Fellow of \n",
      "the Prince’s Trust and is a member of the \n",
      "UK Advisory Council of the British Asian \n",
      "Trust under the patronage of HRH The \n",
      "Prince of Wales.\n",
      "In 2008, Haroon and Farouq were \n",
      "winners of the highly valued Coutts \n",
      "Family Business Prize and widely \n",
      "applauded for the quality and social \n",
      "integrity of the business they created. \n",
      "In 2009, they were both finalists in the \n",
      "Ernst & Young Entrepreneur of the Year \n",
      "Awards and in 2016 they received the \n",
      "Outstanding Contribution Award at \n",
      "the Laing & Buisson Annual Healthcare \n",
      "Awards. In 2019, Haroon and Farouq were \n",
      "winners of the 'Asian Business of the Year'.\n",
      "Haroon, a graduate of the University \n",
      "of London, is a Founder Trustee of the \n",
      "CareTech Charitable Foundation formed \n",
      "in 2017, and is Chairman of the Trustees, \n",
      "working closely with the Foundation’s \n",
      "CEO and independent Trustees.Jamie joined the Board as a Non-\n",
      "Executive Director in 2013. Following \n",
      "a long career in corporate advisory \n",
      "and broking in the City, including \n",
      "acting as Chief Executive Officer of \n",
      "N+1Brewin LLP, and latterly as Senior\n",
      "    History: []\n",
      "\n",
      "    User: Is it true that Haroon Sheikh is the CEO of CareTech?\n",
      "    Chatbot:\n",
      "    It is mandatorian that only if the answer is not in the context, answer \"I have not enough context in order to answer this\" and stop the answer.\n",
      "    Try to use the memory context in the answer only if the question mentions it.\n",
      "\u001b[0m\n",
      " Yes, Haroon Sheikh is the Group CEO of CareTech. He leads the day-to-day running of the Group and has been instrumental in its international expansion, as stated in the context you provided.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Is it true that Haroon Sheikh is the CEO of CareTech?',\n",
       " 'result': ' Yes, Haroon Sheikh is the Group CEO of CareTech. He leads the day-to-day running of the Group and has been instrumental in its international expansion, as stated in the context you provided.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a knowledgeable chatbot, here to help with questions of the user.\n",
    "    Your tone should be professional and informative.\n",
    "\n",
    "    Context: {context}\n",
    "    History: {history}\n",
    "\n",
    "    User: {question}\n",
    "    Chatbot:\n",
    "    It is mandatorian that only if the answer is not in the context, answer \"I have not enough context in order to answer this\" and stop the answer.\n",
    "    Try to use the memory context in the answer only if the question mentions it.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    "    input_key=\"question\"\n",
    ")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=CustomRetriever_advanced(vs = vectorstore, vs_2=vectorstore_bgem3, k=4),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": memory,\n",
    "    }\n",
    ")\n",
    "query = 'Is it true that Haroon Sheikh is the CEO of CareTech?'\n",
    "result = qa_chain({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0\n",
      "scores previos 0.3333333333333333\n",
      "scores previos 1.3333333333333333\n",
      "scores previos 1.8333333333333333\n",
      "scores previos 0.25\n",
      "scores previos 2.1666666666666665\n",
      "scores previos 3.1666666666666665\n",
      "scores previos 0.5\n",
      "scores previos 0.8333333333333333\n",
      "Documentos finales (score)\n",
      "------\n",
      "3.6666666666666665\n",
      "------\n",
      "1.0833333333333333\n",
      "------\n",
      "1.0\n",
      "------\n",
      "0.5\n",
      " {\"score\": \"yes\"} {\n",
      "\"score\": \"yes\"\n",
      "} {\"score\": \"yes\"} {\"score\": \"yes\"}\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a knowledgeable chatbot, here to help with questions of the user.\n",
      "    Your tone should be professional and informative.\n",
      "\n",
      "    Context: and Robert W. Baird for two years until \n",
      "June 2002. Karl set up Ashling Capital \n",
      "LLP in December 2002 to provide \n",
      "consultancy services to quoted \n",
      "and private companies. He sits on a \n",
      "number of AIM quoted and private \n",
      "company boards.January 2020 October 2005\n",
      "Haroon is amongst the most experienced \n",
      "CEOs in the health and social care \n",
      "sector and one of the UK’s leading \n",
      "entrepreneurs and philanthropists. Along \n",
      "with his brother Farouq, he co-founded \n",
      "CareTech. As Group CEO he actively leads \n",
      "the day-to-day running of the Group \n",
      "and its international expansion, and has \n",
      "been instrumental in assembling a highly \n",
      "talented leadership team, to support \n",
      "the continued growth of the business. \n",
      "Haroon brings commercial acumen, \n",
      "related industry experience and property \n",
      "knowledge. He has a deep commitment \n",
      "and passion for delivering high-quality \n",
      "care and support to people with  \n",
      "complex needs. \n",
      "Haroon is Patron and Enterprise Fellow of \n",
      "the Prince’s Trust and is a member of the \n",
      "UK Advisory Council of the British Asian \n",
      "Trust under the patronage of HRH The \n",
      "Prince of Wales.\n",
      "In 2008, Haroon and Farouq were \n",
      "winners of the highly valued Coutts \n",
      "Family Business Prize and widely \n",
      "applauded for the quality and social \n",
      "integrity of the business they created. \n",
      "In 2009, they were both finalists in the \n",
      "Ernst & Young Entrepreneur of the Year \n",
      "Awards and in 2016 they received the \n",
      "Outstanding Contribution Award at \n",
      "the Laing & Buisson Annual Healthcare \n",
      "Awards. In 2019, Haroon and Farouq were \n",
      "winners of the 'Asian Business of the Year'.\n",
      "Haroon, a graduate of the University \n",
      "of London, is a Founder Trustee of the \n",
      "CareTech Charitable Foundation formed \n",
      "in 2017, and is Chairman of the Trustees, \n",
      "working closely with the Foundation’s \n",
      "CEO and independent Trustees.Jamie joined the Board as a Non-\n",
      "Executive Director in 2013. Following \n",
      "a long career in corporate advisory \n",
      "and broking in the City, including \n",
      "acting as Chief Executive Officer of \n",
      "N+1Brewin LLP, and latterly as Senior\n",
      "    History: [HumanMessage(content='Is it true that Haroon Sheikh is the CEO of CareTech?', additional_kwargs={}, response_metadata={}), AIMessage(content=' Yes, Haroon Sheikh is the Group CEO of CareTech. He leads the day-to-day running of the Group and has been instrumental in its international expansion, as stated in the context you provided.', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "    User: Is it true that Haroon Sheikh is the CEO of CareTech?\n",
      "    Chatbot:\n",
      "    It is mandatorian that only if the answer is not in the context, answer \"I have not enough context in order to answer this\" and stop the answer.\n",
      "    Try to use the memory context in the answer only if the question mentions it.\n",
      "\u001b[0m\n",
      " Yes, Haroon Sheikh is the Group CEO of CareTech. He leads the day-to-day running of the Group and has been instrumental in its international expansion, as stated in the context you provided.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, Haroon Sheikh is the Group CEO of CareTech. He leads the day-to-day running of the Group and has been instrumental in its international expansion, as stated in the context you provided.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": query})['result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
